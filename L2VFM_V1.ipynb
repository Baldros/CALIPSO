{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5394bb0b",
   "metadata": {},
   "source": [
    "# Importações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyhdf.SD import SD, SDC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Normalize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2494d166",
   "metadata": {},
   "source": [
    "# Funções Utilizadas:\n",
    "\n",
    "## Dados L2 VFM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d75545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que retorna dados das flags organizadas em arrays de 3 dimensões (lat x perfil x altitude)\n",
    "def reshape_lpa(dado, lat):\n",
    "    size = lat.shape[0] # pega tamanho do array contendo as latitudes\n",
    "    # Aplicando a função reshape em cada intervalo dos dados de acordo com a resolução de cada faixa de altitude\n",
    "    tipo = [np.flip(np.reshape(dado[:,1165:], (size, 15, 290)), 2)]\n",
    "    tipo.append(np.flip(np.reshape(dado[:,165:1165], (size, 5, 200)), 2))\n",
    "    return tipo # retorna lista de 3 elementos com arrays que foram organizados por faixa de altitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f0c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoficando_bits(flags,lat):\n",
    "    \"\"\"\n",
    "    Extrai tipo dos elementos e subtipo dos aerossóis, faz controle de qualidade e reformula array em latitude, \n",
    "    perfil e altitude de acordo com a resolução da faixa de altitude\n",
    "    \"\"\"\n",
    "    # Extraindo elementos dos bits e faz controle de qualidade pelas flags de cq\n",
    "    typesqa = (((flags>>3) & 3)>=2).astype('int')\n",
    "    types =[(flags & 7) * typesqa] # lista com tipo do elemento dos 3 primeiros bits da flag extraido usando mascaramento de bits\n",
    "\n",
    "    # Extrai subtipos aerossóis troposféricos e aerossóis estratosféricos dos bits e faz controle de qualidade pelas flags de cq\n",
    "    subtypeqa = ((flags>>12) & 1)\n",
    "    subtype = ((flags >> 9) & 7) * subtypeqa # extrai o subtipo do elementos dos 3 primeiros bits a esquerda da posição 9\n",
    "    \n",
    "    for tipo in range(3,5):\n",
    "        tmask = (types[0] == tipo) # array de boleano indicando onde o tipo das flags é igual ao tipo do loop\n",
    "        temp1 = (subtype!=0) # array de boleano indicando onde o subtipo das flags é diferente de 0\n",
    "        temp2 = (temp1 & tmask) # array de boleano indicando onde o tipo das flags é igual ao tipo do loop e o subtipo é diferente de zero\n",
    "        subtipo = subtype * temp2 # array que mantém apenas valores dos subtipos onde onde o tipo das flags é igual ao tipo do loop e o subtipo é diferente de zero\n",
    "        types.append(subtipo) # adiciona lista types um array contendo os valores dos subtipos classificados de acordo com os tipos: nevem, aerossol troposférico e aerossol estratosférico respectivamente\n",
    "    # Adiciona a cada classificação os valores de tipos e subtipos em array de 3 dimensões (lat x perfil x altitude)\n",
    "\n",
    "    return [reshape_lpa(type,lat) for type in types]\n",
    "    # return reshape_lpa(types[1],lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac1e0e0",
   "metadata": {},
   "source": [
    "## Dados L3 VFM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_coord(lista_coor, coord):\n",
    "    \"\"\" Função que retorna indice do valor da lista mais proximo ao valor passado \"\"\"\n",
    "    return (np.abs(lista_coor - (coord))).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18467e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_variaveis(dados, lat_n, lat_s, lon_e, lon_w, variavel):\n",
    "    \"\"\"Retorna o valor da variável com corte de área a partir do HDF\"\"\"\n",
    "    # Cria variaveis de lat e lon\n",
    "    dado = dados.copy()\n",
    "    lat = dado.select('Latitude_Midpoint').get()[0]\n",
    "    lon = dado.select('Longitude_Midpoint').get()[0]\n",
    "\n",
    "    # Selecionando índices correspondentes aos pontos mais proximos ao intervalo dado\n",
    "    idx_n_lat, idx_s_lat = idx_coord(lat, lat_n), idx_coord(lat, lat_s)\n",
    "    idx_e_lon, idx_w_lon = idx_coord(lon, lon_e), idx_coord(lon, lon_w)\n",
    "\n",
    "    dado = dado.select(variavel)[int(idx_s_lat):int(idx_n_lat) + 1,\n",
    "                                 int(idx_w_lon):int(idx_e_lon) + 1]\n",
    "    dado = dado.astype('float')\n",
    "    dado[dado == -9999] = np.nan\n",
    "    if 'Extinction_Coefficient_532_Mean' in variavel:\n",
    "        dado[dado < 0] = np.nan\n",
    "        dado[dado > 4] = np.nan\n",
    "    elif 'AOD_Mean' in variavel:\n",
    "        dado[dado < 0] = np.nan\n",
    "        dado[dado > 5] = np.nan\n",
    "    else:\n",
    "        dado[dado < 0] = np.nan\n",
    "        dado[dado > 32767] = np.nan\n",
    "    return dado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def porc_passou_qc(dados):\n",
    "    dado = dados.copy()\n",
    "    return (dado.size - np.count_nonzero(np.isnan(dado)))/dado.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ddd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_espacial(dado):\n",
    "    med_esp = np.nanmean(np.nanmean(dado, axis=0), axis=0)\n",
    "    return med_esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_estacao_det_tipo(dados):\n",
    "    dado = dados.copy()\n",
    "    det_tipo = pd.concat(dado, axis=1).T\n",
    "    det_tipo.index.rename(['mês', 'tipo'], inplace=True)\n",
    "    # Criando indice com estação e ano\n",
    "    det_tipo['Estacão_ano'] = ['INVERNO ' + x[:4] if 6 <= int(x[-2:]) <= 8\n",
    "                               else 'PRIMAVERA ' + x[:4] if 9 <= int(x[-2:]) <= 11\n",
    "                               else 'VERÃO ' + str(int(x[:4]) + 1) if x[-2:] == '12'\n",
    "                               else 'VERÃO ' + x[:4] if int(x[-2:]) <= 2\n",
    "                               else 'OUTONO ' + x[:4] for x in det_tipo.index.get_level_values(0)]\n",
    "    det_tipo = det_tipo.set_index('Estacão_ano', append=True)\n",
    "\n",
    "    # Excluir estações dos anos que não tem 3 meses para compor a média sazonal\n",
    "    unique, counts = np.unique(det_tipo.groupby(\n",
    "        level=[0, 2]).count().index.get_level_values(1), return_counts=True)\n",
    "    meses_est = dict(zip(unique, counts))\n",
    "    excluir = [mes for mes in meses_est.keys() if meses_est[mes] < 3]\n",
    "    det_tipo.drop(excluir, level=2, axis=0, inplace=True)\n",
    "    # Fazendo a média sazonal para cada ano\n",
    "    det_tipo = det_tipo.groupby(level=[2, 1]).mean()\n",
    "    return det_tipo.loc[(det_tipo != 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_estacao_uni(dados):\n",
    "    dado = dados.copy()\n",
    "    # dado = pd.DataFrame.from_dict(dado, orient='index')\n",
    "\n",
    "    dado['Estacão_ano'] = ['INVERNO ' + x[:4] if 6 <= int(x[-2:]) <= 8\n",
    "                           else 'PRIMAVERA ' + x[:4] if 9 <= int(x[-2:]) <= 11\n",
    "                           else 'VERÃO ' + str(int(x[:4]) + 1) if x[-2:] == '12'\n",
    "                           else 'VERÃO ' + x[:4] if int(x[-2:]) <= 2\n",
    "                           else 'OUTONO ' + x[:4] for x in dado.index]\n",
    "    dado = dado.set_index('Estacão_ano')\n",
    "\n",
    "    # Verificando quais estações de cada ano contam com os 3 meses para compor a média sazonal do ano\n",
    "    unique, counts = np.unique(dado.index, return_counts=True)\n",
    "    meses_est = dict(zip(unique, counts))\n",
    "    excluir = [mes for mes in meses_est.keys() if meses_est[mes] < 3]\n",
    "    # Removendo dados das estações que não tem 3 meses para a média\n",
    "    dado.drop(excluir, axis=0, inplace=True)\n",
    "    return dado.groupby(level=[0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93602866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_periodo_uni(dados):\n",
    "    dado = dados.copy()\n",
    "    return dado.groupby([dado.index.get_level_values(0).str[:-5]]).agg(['mean', 'std']).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_periodo_det_tipo(dados):\n",
    "    dado = dados.copy()\n",
    "    media = dado.groupby([dado.index.get_level_values(\n",
    "        0).str[:-5], dado.index.get_level_values(1)]).agg(['mean', 'std']).stack()\n",
    "    return media.loc[(media != 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b5959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalia_estacao(med_est, media_per):\n",
    "    media_per = media_per.reorder_levels([1, 0], axis=1)\n",
    "    media_per = media_per['mean']\n",
    "    for estacao in media_per.columns:\n",
    "        med_est[[col for col in med_est.columns if estacao in col]] = med_est[[\n",
    "            col for col in med_est.columns if estacao in col]].sub(media_per[estacao], axis=0)\n",
    "    return med_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11226541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalia_tipos(med_est, media_per):\n",
    "    anom_dict = {}\n",
    "    estacoes = ['INVERNO', 'PRIMAVERA', 'VERÃO', 'OUTONO']\n",
    "    media_per = media_per.reorder_levels([2, 0, 1], axis=1)\n",
    "    media_per = media_per['mean']\n",
    "    for estacao in estacoes:\n",
    "        anom_dict[estacao] = med_est[[col for col in med_est.columns.unique(\n",
    "            level=0) if estacao in col]].sub(media_per[estacao], axis=0)\n",
    "    # return anom_dict\n",
    "    return pd.concat(anom_dict, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13d2d0",
   "metadata": {},
   "source": [
    "# Funções de Auxílio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76105dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_district(path):\n",
    "    '''\n",
    "        Não acho que seria interessante misturar os arquivos HDFs com outros arquivos,\n",
    "    porém, do jeito que está configurada a minha organização das pastas, não há a necessidade\n",
    "    de gerar outra entrada para dizer onde as imagens serão salvas.\n",
    "    \n",
    "        Essa função então, foi construida para cumprir esse propósito, a ideia aqui é\n",
    "    reorganizar o caminho dos diretório para que as imagens sejam salvas de forma organizada.\n",
    "    '''\n",
    "    \n",
    "    # Acrescentando um termo para gerar outro diretório:\n",
    "    img_diretorio = path+'_img'\n",
    "    \n",
    "    # Caso a pasta não tenha sido criada previamente:\n",
    "    if not os.path.exists(img_diretorio):\n",
    "        os.mkdir(img_diretorio)\n",
    "        \n",
    "    return img_diretorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf_path(diretorio, faixa_ano=None):\n",
    "    '''\n",
    "    Retorna uma lista de caminhos para arquivos HDF que estão no diretório fornecido e na faixa de anos especificada.\n",
    "    '''\n",
    "    if faixa_ano is None:\n",
    "        faixa_ano = []\n",
    "\n",
    "    # Obter o ano inicial e o ano final da faixa de anos\n",
    "    ano_inicial = min(faixa_ano) if faixa_ano else None\n",
    "    ano_final = max(faixa_ano) if faixa_ano else None\n",
    "\n",
    "    hdf_files = []\n",
    "    for filename in os.listdir(diretorio):\n",
    "        if filename.endswith(\".hdf\"):\n",
    "            ano_local = int(filename[51:55])\n",
    "            # Verificar se o ano do arquivo está dentro da faixa de anos\n",
    "            if (ano_inicial is None or ano_local >= int(ano_inicial)) and (ano_final is None or ano_local <= int(ano_final)):\n",
    "                hdf_path = os.path.join(diretorio, filename)\n",
    "                hdf_files.append(hdf_path)   \n",
    "    return hdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea6af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = input('Digire o diretório completo contendo inclusive a pasta onde estão os arquivos:\\n')\n",
    "area = path[-1]\n",
    "# Inervalo de Tempo:\n",
    "ano_inicial = input('Data de Inicio(Ano): ')\n",
    "ano_final = input('Data de Final(Ano): ')\n",
    "\n",
    "    \n",
    "if ano_inicial == '':\n",
    "    ano_inicial = '2006'\n",
    "    \n",
    "elif int(ano_inicial) < 2006:\n",
    "    print('Não existe valores anteriores a 2006')\n",
    "\n",
    "    \n",
    "if ano_final == '':\n",
    "    ano_final = '2022'\n",
    "    \n",
    "elif int(ano_final) > 2022:\n",
    "    print('Não existe valores maiores que 2022')\n",
    "\n",
    "files = hdf_path(path, [ano_inicial,ano_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6620a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe674e",
   "metadata": {},
   "source": [
    "# Importando Arquivos:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25361560",
   "metadata": {},
   "source": [
    "path = input('Digire o diretório completo contendo inclusive a pasta onde estão os arquivos:\\n')\n",
    "area = path[-1]\n",
    "hdf_files = [os.path.join(path, filename) for filename in os.listdir(path) if filename.endswith(\".hdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "cidade = input('Digite o nome da cidade: ')\n",
    "\n",
    "if cidade == \"\":\n",
    "    cidade = 'Bahia'\n",
    "    print('valor defaut atribuido')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4279b1e2",
   "metadata": {},
   "source": [
    "# Análise e Classifição de Elemento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72226d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o dicionário\n",
    "#Vendo de um em um (iterando) os arquivos\n",
    "meses_ano = set()\n",
    "# dados = {'elementos':{},'aero_tro':{},'aero_est':{}}\n",
    "dados = {'elementos':{}, 'Aerossóis_Troposféricos':{}, 'Aerossóis_Estratosféricos':{}}\n",
    "for file in files:\n",
    "    arquivo = file.split('\\\\')[-1]\n",
    "    meses_ano.add(arquivo[30:37])\n",
    "    passagem = arquivo[30:-22]+' '+arquivo[-21:-19]+':'+arquivo[-18:-16]+':'+arquivo[-15:-12]\n",
    "    hdf = SD(file,SDC.READ)\n",
    "    flags = hdf.select('Feature_Classification_Flags')[:,:] # copiar as flags de classificação    \n",
    "    lat = hdf.select('Latitude').get().flatten() # Copia valores de latitude de array com duas latitudes para array de uma dimensão\n",
    "    classificacoes = decoficando_bits(flags,lat)\n",
    "    for chave, classificacao in zip(dados.keys(), classificacoes):\n",
    "        dados[chave][passagem] = classificacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar arrays de detecções diáriária por lat x perfil x altitude em detecções mensais por área x altitude\n",
    "# Lista com os meses\n",
    "# passagens = dados['aero_tro'].keys()\n",
    "passagens = dados['Aerossóis_Troposféricos'].keys()\n",
    "classificacao_mensal = {}\n",
    "for clasf in dados.keys():\n",
    "    classificacao_mensal[clasf]={}\n",
    "    for mes_ano in meses_ano:\n",
    "        clasf_mes_0 = None  # Variável onde salvaremos um array com todas as classificações para todos as latitudes, perfis, dias por altura\n",
    "        clasf_mes_1 = None  # Variável onde salvaremos um array com todas as classificações para todos as latitudes, perfis, dias por altura\n",
    "        for passagem in passagens:\n",
    "            if mes_ano == passagem[:7]:\n",
    "                # Caso a variável de clasf_mes ainda esteja vazia\n",
    "                if clasf_mes_0 is None:\n",
    "                    clasf_mes_0 = dados[clasf][passagem][0].reshape(-1, dados[clasf][passagem][0].shape[-1])\n",
    "                    clasf_mes_1 = dados[clasf][passagem][1].reshape(-1, dados[clasf][passagem][1].shape[-1])\n",
    "                else:\n",
    "                    clasf_mes_0 = np.vstack((clasf_mes_0, dados[clasf][passagem][0].reshape(-1, dados[clasf][passagem][0].shape[-1])))\n",
    "                    clasf_mes_1 = np.vstack((clasf_mes_1, dados[clasf][passagem][1].reshape(-1, dados[clasf][passagem][1].shape[-1])))\n",
    "        classificacao_mensal[clasf][mes_ano] = [clasf_mes_0, clasf_mes_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470380df",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_total = {'Aerossóis_Troposféricos':{}, 'Aerossóis_Estratosféricos':{}}\n",
    "for clasf in freq_total.keys():\n",
    "    for mes_ano in meses_ano:\n",
    "        freq_total[clasf][mes_ano] = [pd.DataFrame(np.count_nonzero(classificacao_mensal[clasf][mes_ano][0], axis=0), columns=[mes_ano])/classificacao_mensal[clasf][mes_ano][0].shape[0],\n",
    "                    pd.DataFrame(np.count_nonzero(classificacao_mensal[clasf][mes_ano][1], axis=0), columns=[mes_ano])/classificacao_mensal[clasf][mes_ano][1].shape[0]]\n",
    "        freq_total[clasf][mes_ano] = pd.concat(freq_total[clasf][mes_ano], axis=0, ignore_index=True)\n",
    "\n",
    "    freq_total[clasf] = pd.concat(freq_total[clasf].values(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d69a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando média sazonal por ano, sazonal por período e anomalia da detecção total dos aerossóis troposféricos\n",
    "freq_total_med_estacao = med_estacao_uni(freq_total['Aerossóis_Troposféricos'].T)\n",
    "freq_total_med_periodo = med_periodo_uni(freq_total_med_estacao)\n",
    "anomalia_freq_total = anomalia_estacao(freq_total_med_estacao.T,freq_total_med_periodo.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa7151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfil vertical do total de detecções de aerossóis troposféricos \n",
    "estacoes = ['INVERNO','PRIMAVERA','VERÃO','OUTONO']\n",
    "alt_0_8 = [round(-0.5 + x*0.03, 2) for x in range(0,290)]\n",
    "alt_8_20 = [round(8.2 + x*0.06, 2) for x in range(0,200)]\n",
    "alt= alt_0_8+alt_8_20\n",
    "fig, ax = plt.subplots(figsize = (6,6), facecolor='white')\n",
    "for estacao in estacoes:\n",
    "    ax.plot(freq_total_med_periodo.T[estacao, 'mean'],alt)\n",
    "    ax.fill_betweenx( alt, freq_total_med_periodo.T[estacao, 'mean']+freq_total_med_periodo.T[estacao, 'std'],\n",
    "    freq_total_med_periodo.T[estacao, 'mean']-freq_total_med_periodo.T[estacao, 'std'], alpha=0.5, label='_nolegend_')\n",
    "\n",
    "    ax.set_xlabel('Detecções (pixel)', fontsize= 10)\n",
    "    ax.set_ylabel('Altura (Km)',fontsize= 10)\n",
    "\n",
    "    ax.set_xlim(0) \n",
    "    ax.set_yticks(np.arange(0,22, 2))\n",
    "    ax.set_xticks(np.arange(0, .8, 0.1))\n",
    "    ax.grid(True)\n",
    "    \n",
    "#plt.title('Média Sazonal - Total Aerossóis Troposféricos')\n",
    "plt.title(f\"(area{area})\")\n",
    "plt.legend(estacoes)\n",
    "#fig.tight_layout()\n",
    "#plt.savefig(fun_district(path) +'\\\\'+cidade + f'_media_sazonal_2006_2021_total_deteccoes(area{area})', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('''\n",
    "    Esse gráfico trata da frequência média de detecções de todos os tipos de aerossóis troposféricos.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac278227",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = {'2006': 'red', '2007': 'coral', '2008': 'rosybrown', '2009': 'orange',\n",
    "         '2010': 'yellow', '2011': 'olivedrab', '2012': 'saddlebrown', '2013': 'yellowgreen',\n",
    "         '2014': 'darkgreen', '2015': 'lime', '2016': 'turquoise', '2017': 'deepskyblue',\n",
    "         '2018': 'slategrey', '2019': 'navy', '2020': 'rebeccapurple', '2021': 'fuchsia',\n",
    "         '2022': 'deeppink'}\n",
    "\n",
    "\n",
    "estacoes = ['INVERNO', 'PRIMAVERA', 'VERÃO', 'OUTONO']\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2,2,figsize = (10,10), facecolor='white', sharex=True, sharey=True)\n",
    "fig.suptitle(f'Total de Detecções de Anomalias Anuais\\n(area{area})')\n",
    "for estacao,ax in zip(estacoes,axs.flatten()):\n",
    "    anos = anomalia_freq_total[[col for col in anomalia_freq_total.columns if estacao in col]].columns\n",
    "    for ano in anos:\n",
    "        ax.plot(anomalia_freq_total[ano], alt, color = cores[ano[-4:]])\n",
    "    ax.legend([col[-4:] for col in anos if estacao in col])\n",
    "    ax.set_title(estacao)\n",
    "    ax.axvline(color = 'black',linewidth=1)\n",
    "    ax.set_ylim(0,22)\n",
    "    ax.grid(True)\n",
    "    ax.set_ylabel('Altura (Km)',fontsize= 10)   \n",
    "    ax.set_xlabel('Frequência de Detecções', fontsize= 10)\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig(fun_district(path) +'\\\\'+ cidade + f'_anomalia_total_deteccoes(area{area})', bbox_inches='tight')\n",
    "plt.show()\n",
    "print('''\n",
    "    Frequencia de detecções das anomalias anuais de todos os aressóis troposféricos de cada uma das estação em relação a média da própria estação. \n",
    "    \n",
    "    Explicação da Beca:Anomalia sazonal anual das detecções de aerossóis troposféricos em relação a média sazonal de detecção de aerossóis troposféricos\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1315543",
   "metadata": {},
   "outputs": [],
   "source": [
    "deteccoes = {}\n",
    "frequencia_tipo = {}\n",
    "for mes_ano in meses_ano:\n",
    "    # Uma lista vazia para cada faixa de altitude onde serão incluidas as contagens para cada altura\n",
    "    deteccoes[mes_ano] = [[], []]\n",
    "    # Olhando cada faixa de altitude\n",
    "    for fx_alt in range(len(classificacao_mensal['Aerossóis_Troposféricos'][mes_ano])):\n",
    "        # print(classificacao_mensal['Aerossóis_Troposféricos'][mes_ano][fx_alt].shape)\n",
    "        # Olhando o array de cada altitude\n",
    "        for alt in range(len(classificacao_mensal['Aerossóis_Troposféricos'][mes_ano][fx_alt][0, :])):\n",
    "            # Retorna valores únicos encontrados no array de cada altura e quantas sua contagem\n",
    "            \n",
    "            unique, counts = np.unique(\n",
    "                classificacao_mensal['Aerossóis_Troposféricos'][mes_ano][fx_alt][:, alt], return_counts=True)\n",
    "            # Adiciona a lista contagem de cada aerossol para cada altura\n",
    "            deteccoes[mes_ano][fx_alt].append(dict(zip(unique, counts)))\n",
    " \n",
    "        deteccoes[mes_ano][fx_alt] = pd.DataFrame(deteccoes[mes_ano][fx_alt])  # Transformando em df\n",
    "        # Excluindo coluna 0 que corresponde a aerossóis não detectados\n",
    "        deteccoes[mes_ano][fx_alt].drop(columns=[0], inplace=True) \n",
    "    # Dividindo o valor de detecções de cada aerossol do df pela quantidade de amostras em pixels para obter frequência\n",
    "    frequencia_tipo[mes_ano] = [deteccoes[mes_ano][0]/classificacao_mensal['Aerossóis_Troposféricos'][mes_ano][0].shape[0],\n",
    "                            deteccoes[mes_ano][1]/classificacao_mensal['Aerossóis_Troposféricos'][mes_ano][1].shape[0]]\n",
    "    frequencia_tipo[mes_ano] = pd.concat(frequencia_tipo[mes_ano], ignore_index=True).fillna(0)\n",
    "                            \n",
    "    deteccoes[mes_ano] = pd.concat(deteccoes[mes_ano], ignore_index=True)\n",
    "    \n",
    "import collections\n",
    "deteccoes = collections.OrderedDict(sorted(deteccoes.items()))\n",
    "frequencia_tipo = collections.OrderedDict(sorted(frequencia_tipo.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c199e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_freq_estacao = med_estacao_det_tipo(frequencia_tipo)\n",
    "med_freq_periodo = med_periodo_det_tipo(med_freq_estacao)\n",
    "anomalia_freq = anomalia_tipos(med_freq_estacao.T, med_freq_periodo.T)\n",
    "\n",
    "med_freq_periodo = med_freq_periodo.T.rename({1: 'Marinho Limpo', 2: 'Poeira', 3: 'Poluição Continental/Fumaça',\n",
    "                                    4: 'Continental Limpo', 5: 'Poeira Poluída', 6: 'Fumaça Elevada', 7: 'Poeira Marinha'}, level=1, axis=1)\n",
    "med_freq_estacao = med_freq_estacao.T.rename({1: 'Marinho Limpo', 2: 'Poeira', 3: 'Poluição Continental/Fumaça',\n",
    "                                    4: 'Continental Limpo', 5: 'Poeira Poluída', 6: 'Fumaça Elevada', 7: 'Poeira Marinha'}, level=1, axis=1)\n",
    "anomalia_freq = anomalia_freq.rename({1: 'Marinho Limpo', 2: 'Poeira', 3: 'Poluição Continental/Fumaça',\n",
    "                            4: 'Continental Limpo', 5: 'Poeira Poluída', 6: 'Fumaça Elevada', 7: 'Poeira Marinha'}, level=2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_estacao = med_estacao_det_tipo(deteccoes)\n",
    "med_periodo = med_periodo_det_tipo(med_estacao)\n",
    "anomalia = anomalia_tipos(med_estacao.T, med_periodo.T)\n",
    "med_periodo = med_periodo.T.rename({1: 'Marinho Limpo', 2: 'Poeira', 3: 'Poluição Continental/Fumaça',\n",
    "                                    4: 'Continental Limpo', 5: 'Poeira Poluída', 6: 'Fumaça Elevada', 7: 'Poeira Marinha'}, level=1, axis=1)\n",
    "med_estacao = med_estacao.T.rename({1: 'Marinho Limpo', 2: 'Poeira', 3: 'Poluição Continental/Fumaça',\n",
    "                                    4: 'Continental Limpo', 5: 'Poeira Poluída', 6: 'Fumaça Elevada', 7: 'Poeira Marinha'}, level=1, axis=1)\n",
    "anomalia = anomalia.rename({1: 'Marinho Limpo', 2: 'Poeira', 3: 'Poluição Continental/Fumaça',\n",
    "                            4: 'Continental Limpo', 5: 'Poeira Poluída', 6: 'Fumaça Elevada', 7: 'Poeira Marinha'}, level=2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = {'2006': 'red', '2007': 'coral', '2008': 'rosybrown', '2009': 'orange',\n",
    "         '2010': 'yellow', '2011': 'olivedrab', '2012': 'saddlebrown', '2013': 'yellowgreen',\n",
    "         '2014': 'darkgreen', '2015': 'lime', '2016': 'turquoise', '2017': 'deepskyblue',\n",
    "         '2018': 'slategrey', '2019': 'navy', '2020': 'rebeccapurple', '2021': 'fuchsia',\n",
    "         '2022': 'deeppink'}\n",
    "tipos = ['Marinho Limpo', 'Poeira', 'Poluição Continental/Fumaça',\n",
    "         'Continental Limpo', 'Poeira Poluída', 'Fumaça Elevada', 'Poeira Marinha']\n",
    "\n",
    "estacoes = ['INVERNO', 'PRIMAVERA', 'VERÃO', 'OUTONO']\n",
    "alt_0_8 = [round(-0.5 + x*0.03, 2) for x in range(0,290)]\n",
    "alt_8_20 = [round(8.2 + x*0.06, 2) for x in range(0,200)]\n",
    "alt= alt_0_8+alt_8_20\n",
    "\n",
    "anom_tipo = anomalia_freq.copy().fillna(0)\n",
    "anom_tipo.columns = anom_tipo.columns.reorder_levels([2, 0, 1])\n",
    "for tipo in tipos:\n",
    "    try:\n",
    "        fig, axs = plt.subplots(2,2,figsize = (10,10), facecolor='white', sharex=True, sharey=True)\n",
    "        for estacao, ax in zip(estacoes, axs.flatten()):\n",
    "            anos = anom_tipo[tipo][estacao].columns.unique(level=0)\n",
    "            ax.set_title(estacao)\n",
    "            for ano in anos:\n",
    "                ax.plot(anom_tipo[tipo][estacao][ano], alt, color=cores[ano[-4:]])\n",
    "    \n",
    "            ax.axvline(color='black', linewidth=1)\n",
    "            ax.set_ylim(0, 22)\n",
    "            ax.set_xlabel('Frequencia de Detecções', fontsize=10)\n",
    "            ax.legend([x[-4:] for x in anos])\n",
    "        fig.suptitle(tipo+f\"(area{area})\")\n",
    "        fig.tight_layout()\n",
    "        #plt.savefig(fun_district(path) +'\\\\' + cidade + '_anomalia_deteccao_tipo' + tipo.replace(' ', '_').replace('/', '_')+f'(area{area})', bbox_inches='tight')\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(f'Não tem a o aerossol do tipo {tipo}')\n",
    "print('''\n",
    "    O mesmo do gráfico de cima para cada tipo de aerossol.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfil vertical das detecções sazonais de cada tipo de aerossol\n",
    "med_detec = med_freq_periodo.reorder_levels([0,2,1], axis = 1).fillna(0)\n",
    "fig, axs = plt.subplots(2,2,figsize = (7,7), facecolor='white', sharex=True, sharey=True)\n",
    "estacoes = ['INVERNO', 'PRIMAVERA', 'VERÃO', 'OUTONO']\n",
    "\n",
    "alt_0_8 = [round(-0.5 + x*0.03, 2) for x in range(0,290)]\n",
    "alt_8_20 = [round(8.2 + x*0.06, 2) for x in range(0,200)]\n",
    "alt= alt_0_8+alt_8_20\n",
    "\n",
    "for estacao,ax in zip(estacoes,axs.flatten()):\n",
    "    for tipo in med_detec[estacao]['mean'].columns:\n",
    "        ax.plot(med_detec[estacao]['mean'][tipo],alt, label=tipo)\n",
    "        ax.fill_betweenx(alt, med_detec[estacao]['mean'][tipo]+med_detec[estacao]['std'][tipo],\n",
    "        med_detec[estacao]['mean'][tipo]-med_detec[estacao]['std'][tipo], alpha=0.5, label='_nolegend_')\n",
    "    \n",
    "    ax.set_xlabel('Frequencia de Detecções', fontsize= 10)\n",
    "    ax.set_ylabel('Altura (Km)',fontsize= 10)\n",
    "    ax.set_title(estacao)\n",
    "    ax.set_xlim(0) \n",
    "    # # ax.locator_params(axis = 'x',  min_n_ticks=6)\n",
    "    # ax.set_xticks(np.arange(0,1000, 150)) \n",
    "    ax.set_yticks(np.arange(0,22, 2))\n",
    "    ax.set_xticks(np.arange(0, 0.6, 0.1))\n",
    "    ax.grid(True)\n",
    "\n",
    "#fig.suptitle('MÉDIA DA DETECÇÃO POR TIPO DE AEROSSÓIS TROPOSFÉRICOS\\n(JUN/2011- MAI/2016)',fontsize= 10)\n",
    "\n",
    "lgd = fig.legend(['Poeira', 'Poluição Continental/Fumaça', 'Continental Limpo','Poeira Poluída', 'Fumaça Elevada'],\n",
    "loc='lower left', bbox_to_anchor=(0.05, -.07),  ncol=3)\n",
    "\n",
    "#fig.tight_layout()\n",
    "fig.suptitle(f\"(area{area})\")\n",
    "#plt.savefig(fun_district(path) +'\\\\'+ cidade + f'_media_sazonal_2006_2021_deteccoes_tipo(area{area})', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('''\n",
    "    Média sazonal de cada tipo de aerossol troposférico\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
